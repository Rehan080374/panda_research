{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store csv file in a Pandas DataFrame\n",
    "df = pd.read_csv('combined_labled_k6.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df.cluster, prefix='base')\n",
    "y.rename(columns = {'base_0':'base_line', 'base_1':'rotation', 'base_2':'translation'}, inplace = True)\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot( x='rotation', data=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.array(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:-1]\n",
    "\n",
    "X=np.array(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=None,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X1= scaler.fit_transform(X)\n",
    "x1 = scaler.transform(X1)\n",
    "\n",
    "print(X1.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = MinMaxScaler()\n",
    "\n",
    "# y1= sc.fit_transform(y.reshape(-1,1))\n",
    "# #y1 = sc.transform(y1)\n",
    "\n",
    "\n",
    "print(y.shape)\n",
    "print(y[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train dataclass TrainData(Dataset):\n",
    "#from http.client import _DataType\n",
    "\n",
    "\n",
    "class TrainData(Dataset):   \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        self.window=5\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if index>= self.length-self.window:\n",
    "            X=self.X_data[index:index+self.window,]\n",
    "            Y=self.y_data[index,]\n",
    "        else:\n",
    "            X=self.X_data[index:index+self.window,]  \n",
    "            Y=self.y_data[index+self.window,]\n",
    "        \n",
    "        return X,Y\n",
    "        \n",
    "    def __len__ (self):\n",
    "        Q = len(self.X_data)\n",
    "        self.length=Q-self.window+1\n",
    "        return self.length\n",
    "\n",
    "# train_data = TrainData(torch.FloatTensor(X_train), \n",
    "#                        torch.FloatTensor(y_train))\n",
    "\n",
    "## test data  \n",
    "# class TestData(Dataset):\n",
    "    \n",
    "#     def __init__(self, X_data,y_data):\n",
    "#         self.X_data = X_data\n",
    "#         self.y_data = y_data\n",
    "#         self.window=5\n",
    "#     def __getitem__(self, index):\n",
    "#         if index>= self.length-self.window:\n",
    "#             X=self.X_data[index:index+self.window]\n",
    "#             Y=self.y_data[index,]\n",
    "\n",
    "#         else:\n",
    "#             X=self.X_data[index:index+self.window]  \n",
    "#             Y=self.y_data[index+self.window,]\n",
    "        \n",
    "#         return X,Y\n",
    "#     def __len__ (self):\n",
    "#         Q = len(self.X_data)\n",
    "#         self.length=Q-self.window+1\n",
    "#         return self.length\n",
    "    \n",
    "\n",
    "#test_data = TrainData(torch.FloatTensor(X_test),torch.FloatTensor(y_test))                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=TrainData(torch.FloatTensor(X1),torch.FloatTensor(y))\n",
    "train_l=round(int(cs.__len__())*0.8)\n",
    "\n",
    "batch_size=25\n",
    "val_l=int(cs.__len__())-train_l\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(cs, [train_l, val_l])\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "\n",
    "for each_x, each_y in train_loader:\n",
    "    print(each_x.shape)\n",
    "    print(each_y.shape)\n",
    "    print(type(each_x))\n",
    "    print(type(each_y))\n",
    "    break\n",
    "    \n",
    "    \n",
    "val_loader = DataLoader(val_set, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "for each_x, each_y in val_loader:\n",
    "    print(each_x.shape)\n",
    "    print(each_y.shape)\n",
    "    print(type(each_x))\n",
    "    print(type(each_y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# batch_size=25\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "\n",
    "# val_loader = DataLoader(dataset=test_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "# print(next(iter(train_loader))[0].shape[0])\n",
    "# #print(train_loader.batch_size)\n",
    "# for each_x, each_y in train_loader:\n",
    "#     print(each_x.shape)\n",
    "#     print(each_y.shape)\n",
    "#     break\n",
    "    \n",
    "    \n",
    "\n",
    "# for each_x,each_y in val_loader:\n",
    "#     print(each_x.shape)\n",
    "#     print(each_y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        #print(x,h)\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_loader, learn_rate, hidden_dim=256, EPOCHS=5, model_type=\"GRU\"):\n",
    "    print(next(iter(train_loader))[0].shape[2])\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]\n",
    "    output_dim = 3\n",
    "    n_layers = 1\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.time()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device), h)\n",
    "            loss = criterion(out, label.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            if counter%200 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.time()\n",
    "        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss/len(train_loader)))\n",
    "        print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, label_scalers):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.time()\n",
    "    for each_x,each_y in val_loader:\n",
    "        inp = (each_x.to(device))\n",
    "        labs = (each_y.to(device))\n",
    "        h = model.init_hidden(inp.shape[0])\n",
    "        # print(inp.size)\n",
    "        out, h = model(inp, h)\n",
    "        outputs.extend(out.cpu().detach().numpy())#.reshape(1, -1)[0])\n",
    "        targets.extend(each_y.cpu().numpy())#.reshape(1, -1)[0])\n",
    "    print(\"Evaluation Time: {}\".format(str(time.time()-start_time)))\n",
    "    \n",
    "    return outputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "gru_model = train(train_loader, lr, model_type=\"GRU\")\n",
    "#Lstm_model = train(train_loader, lr, model_type=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_outputs, targets = evaluate(gru_model, val_loader, label_scalers=y_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gru_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=pd.dataframe(gru_outputs)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=np.array(gru_outputs)\n",
    "data = pd.DataFrame(output, columns = ['base','rotation','translation'])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=np.array(targets)\n",
    "dat = pd.DataFrame(out, columns = ['base1','rotation1','translation1'])\n",
    "dat.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import tanh\n",
    "r=[]\n",
    "\n",
    "res = output.max(axis=1)\n",
    "print(type(res))\n",
    "for i in res:\n",
    "    print(i)\n",
    "#     r.append (tanh(res[i]))    \n",
    "plt.plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['base1'] = dat.base1\n",
    "data['rotation1'] = dat.rotation1\n",
    "data['translation1'] = dat.translation1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"results_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
