{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>joint_effort[0]</th>\n",
       "      <th>joint_effort[1]</th>\n",
       "      <th>joint_effort[2]</th>\n",
       "      <th>joint_effort[3]</th>\n",
       "      <th>joint_effort[4]</th>\n",
       "      <th>joint_effort[5]</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.050352</td>\n",
       "      <td>0.036084</td>\n",
       "      <td>0.153670</td>\n",
       "      <td>-0.208722</td>\n",
       "      <td>-0.226335</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.040706</td>\n",
       "      <td>0.052485</td>\n",
       "      <td>0.160204</td>\n",
       "      <td>-0.204533</td>\n",
       "      <td>-0.222889</td>\n",
       "      <td>0.070273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.070528</td>\n",
       "      <td>0.033901</td>\n",
       "      <td>0.198342</td>\n",
       "      <td>-0.208156</td>\n",
       "      <td>-0.228432</td>\n",
       "      <td>0.070408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.078726</td>\n",
       "      <td>0.032952</td>\n",
       "      <td>0.203791</td>\n",
       "      <td>-0.208763</td>\n",
       "      <td>-0.228608</td>\n",
       "      <td>0.071877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.046257</td>\n",
       "      <td>0.048101</td>\n",
       "      <td>0.215115</td>\n",
       "      <td>-0.205263</td>\n",
       "      <td>-0.223011</td>\n",
       "      <td>0.071184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   samples  joint_effort[0]  joint_effort[1]  joint_effort[2]  \\\n",
       "0        0         1.050352         0.036084         0.153670   \n",
       "1        1         1.040706         0.052485         0.160204   \n",
       "2        2         1.070528         0.033901         0.198342   \n",
       "3        3         1.078726         0.032952         0.203791   \n",
       "4        4         1.046257         0.048101         0.215115   \n",
       "\n",
       "   joint_effort[3]  joint_effort[4]  joint_effort[5]  cluster  \n",
       "0        -0.208722        -0.226335         0.071900        0  \n",
       "1        -0.204533        -0.222889         0.070273        0  \n",
       "2        -0.208156        -0.228432         0.070408        0  \n",
       "3        -0.208763        -0.228608         0.071877        0  \n",
       "4        -0.205263        -0.223011         0.071184        0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store csv file in a Pandas DataFrame\n",
    "df = pd.read_csv('combined_labled_k6.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a8aa6c640>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'cluster', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:-1]\n",
    "y = df.iloc[:, -1]\n",
    "X=np.array(X)\n",
    "y= np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05035197,  0.03608361,  0.15366994, -0.20872176, -0.22633529,\n",
       "         0.07190013],\n",
       "       [ 1.04070593,  0.05248472,  0.16020391, -0.20453307, -0.22288895,\n",
       "         0.07027318],\n",
       "       [ 1.07052848,  0.03390063,  0.19834174, -0.20815593, -0.22843161,\n",
       "         0.07040757],\n",
       "       ...,\n",
       "       [ 2.18775072,  0.72399379, -0.04694298, -0.1240152 , -0.3555519 ,\n",
       "        -0.3742596 ],\n",
       "       [ 2.17323085,  0.76483473, -0.16630029, -0.11638658, -0.3595942 ,\n",
       "        -0.37862044],\n",
       "       [ 2.21371423,  0.70888995, -0.01968097, -0.12413878, -0.36091259,\n",
       "        -0.37732746]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.reshape(-1,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28670, 6)\n",
      "(7168, 6)\n",
      "(28670, 1)\n",
      "(7168, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train dataclass TrainData(Dataset):\n",
    "#from http.client import _DataType\n",
    "\n",
    "\n",
    "class TrainData(Dataset):   \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        self.window=5\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if index>= self.length-self.window:\n",
    "            X=self.X_data[index:index+self.window,]\n",
    "            Y=self.y_data[index,]\n",
    "        else:\n",
    "            X=self.X_data[index:index+self.window,]  \n",
    "            Y=self.y_data[index+self.window,]\n",
    "        \n",
    "        return X,Y\n",
    "        \n",
    "    def __len__ (self):\n",
    "        Q = len(self.X_data)\n",
    "        self.length=Q-self.window+1\n",
    "        return self.length\n",
    "\n",
    "\n",
    "train_data = TrainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "## test data  \n",
    "# class TestData(Dataset):\n",
    "    \n",
    "#     def __init__(self, X_data,y_data):\n",
    "#         self.X_data = X_data\n",
    "#         self.y_data = y_data\n",
    "#         self.window=5\n",
    "#     def __getitem__(self, index):\n",
    "#         if index>= self.length-self.window:\n",
    "#             X=self.X_data[index:index+self.window]\n",
    "#             Y=self.y_data[index,]\n",
    "\n",
    "#         else:\n",
    "#             X=self.X_data[index:index+self.window]  \n",
    "#             Y=self.y_data[index+self.window,]\n",
    "        \n",
    "#         return X,Y\n",
    "#     def __len__ (self):\n",
    "#         Q = len(self.X_data)\n",
    "#         self.length=Q-self.window+1\n",
    "#         return self.length\n",
    "    \n",
    "\n",
    "test_data = TrainData(torch.FloatTensor(X_test),torch.FloatTensor(y_test))                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "torch.Size([25, 5, 6])\n",
      "torch.Size([25, 1])\n",
      "torch.Size([25, 5, 6])\n",
      "torch.Size([25, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "batch_size=25\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "\n",
    "val_loader = DataLoader(dataset=test_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "print(next(iter(train_loader))[0].shape[0])\n",
    "#print(train_loader.batch_size)\n",
    "for each_x, each_y in train_loader:\n",
    "    print(each_x.shape)\n",
    "    print(each_y.shape)\n",
    "    break\n",
    "    \n",
    "    \n",
    "\n",
    "for each_x,each_y in val_loader:\n",
    "    print(each_x.shape)\n",
    "    print(each_y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        #print(x,h)\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_loader, learn_rate, hidden_dim=256, EPOCHS=5, model_type=\"GRU\"):\n",
    "    print(next(iter(train_loader))[0].shape[2])\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.time()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device), h)\n",
    "            loss = criterion(out, label.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            if counter%200 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.time()\n",
    "        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss/len(train_loader)))\n",
    "        print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y, label_scalers):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.time()\n",
    "    j=0\n",
    "    for i in test_x:\n",
    "        inp = torch.from_numpy(np.array(test_x[j]))\n",
    "        labs = torch.from_numpy(np.array(test_y[j]))\n",
    "        h = model.init_hidden(inp.shape[0])\n",
    "        out, h = model(inp.to(device).float(), h)\n",
    "        outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "        targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "        j+=1\n",
    "    print(\"Evaluation Time: {}\".format(str(time.time()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Starting Training of GRU model\n",
      "Epoch 1......Step: 200/1146....... Average Loss for Epoch: 0.24341930935624986\n",
      "Epoch 1......Step: 400/1146....... Average Loss for Epoch: 0.24998593902448193\n",
      "Epoch 1......Step: 600/1146....... Average Loss for Epoch: 0.2494448852802937\n",
      "Epoch 1......Step: 800/1146....... Average Loss for Epoch: 0.2492673510790337\n",
      "Epoch 1......Step: 1000/1146....... Average Loss for Epoch: 0.2504814660632983\n",
      "Epoch 1/5 Done, Total Loss: 0.2516305697699895\n",
      "Total Time Elapsed: 3499.488090991974 seconds\n",
      "Epoch 2......Step: 200/1146....... Average Loss for Epoch: 0.260341687630862\n",
      "Epoch 2......Step: 400/1146....... Average Loss for Epoch: 0.25887798846699295\n",
      "Epoch 2......Step: 600/1146....... Average Loss for Epoch: 0.24901381958431254\n",
      "Epoch 2......Step: 800/1146....... Average Loss for Epoch: 0.24878525632550008\n",
      "Epoch 2......Step: 1000/1146....... Average Loss for Epoch: 0.2507775096585974\n",
      "Epoch 2/5 Done, Total Loss: 0.2507995098892658\n",
      "Total Time Elapsed: 3.9013826847076416 seconds\n",
      "Epoch 3......Step: 200/1146....... Average Loss for Epoch: 0.23928897187113762\n",
      "Epoch 3......Step: 400/1146....... Average Loss for Epoch: 0.2493729147175327\n",
      "Epoch 3......Step: 600/1146....... Average Loss for Epoch: 0.25433828162029387\n",
      "Epoch 3......Step: 800/1146....... Average Loss for Epoch: 0.24830073542194442\n",
      "Epoch 3......Step: 1000/1146....... Average Loss for Epoch: 0.25288081006519497\n",
      "Epoch 3/5 Done, Total Loss: 0.25054238032205045\n",
      "Total Time Elapsed: 3.4934144020080566 seconds\n",
      "Epoch 4......Step: 200/1146....... Average Loss for Epoch: 0.23830450320616364\n",
      "Epoch 4......Step: 400/1146....... Average Loss for Epoch: 0.24498945044819265\n",
      "Epoch 4......Step: 600/1146....... Average Loss for Epoch: 0.24885233502835036\n",
      "Epoch 4......Step: 800/1146....... Average Loss for Epoch: 0.25476357752690093\n",
      "Epoch 4......Step: 1000/1146....... Average Loss for Epoch: 0.252225148698315\n",
      "Epoch 4/5 Done, Total Loss: 0.2504848149583966\n",
      "Total Time Elapsed: 3.883394241333008 seconds\n",
      "Epoch 5......Step: 200/1146....... Average Loss for Epoch: 0.24596024023368954\n",
      "Epoch 5......Step: 400/1146....... Average Loss for Epoch: 0.2574099419731647\n",
      "Epoch 5......Step: 600/1146....... Average Loss for Epoch: 0.2551421478949487\n",
      "Epoch 5......Step: 800/1146....... Average Loss for Epoch: 0.24990997716784477\n",
      "Epoch 5......Step: 1000/1146....... Average Loss for Epoch: 0.2523097601830959\n",
      "Epoch 5/5 Done, Total Loss: 0.2505781939074423\n",
      "Total Time Elapsed: 3.541508674621582 seconds\n",
      "Total Training Time: 3514.307790994644 seconds\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "gru_model = train(train_loader, lr, model_type=\"GRU\")\n",
    "#Lstm_model = train(train_loader, lr, model_type=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gru_outputs, targets, gru_sMAPE = evaluate(gru_model, X_test, y_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
